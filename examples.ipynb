{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Supporting Modules for this Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import choice\n",
    "from uuid import uuid4\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import LangChain Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_mistralai import ChatMistralAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Globals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug, set_verbose\n",
    "from langchain.callbacks.tracers import ConsoleCallbackHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Keys\n",
    "\n",
    "Be sure you create the appropiate .env file in your folder. This includes your Langsmith Keys.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "mistral_api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "openweather_api_key = os.getenv(\"OPENWEATHER_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template Creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a very friendly and helpful Assistant. Please help the user with their queries. User: {query}\"\n",
    "prompt = ChatPromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pirate Template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pirate_template = \"Avast, me hearty! Ye be a friendly and helpful Assistant. Translate this sentence into Pirate, the language of the high seas. I be askin' ye to translate this here passage fer me, if ye please. {passage}\"\n",
    "pirate_prompt = ChatPromptTemplate.from_template(template=pirate_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM creation\n",
    "\n",
    "In this example we are using Google Gemini and Anthropics Claude 2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_llm = ChatGoogleGenerativeAI(google_api_key=google_api_key, model=\"gemini-pro\")\n",
    "anthropic_llm = ChatAnthropic(api_key=anthropic_api_key, model=\"claude-3-opus-20240229\")\n",
    "mistral_llm = ChatMistralAI(model=\"mistral-large-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCEL Creation\n",
    "\n",
    "### Basic Query\n",
    "\n",
    "Here we'll create a few basic invokes and chains for our demonstration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic query\n",
    "\n",
    "basic_query_g = prompt | gemini_llm | StrOutputParser()\n",
    "basic_query_a = prompt | anthropic_llm | StrOutputParser()\n",
    "basic_query_m = prompt | mistral_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining\n",
    "\n",
    "Next let's create a simple chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple chain that translates an LLM output into pirate\n",
    "\n",
    "# User's query -> Google LLM -> Google LLM output -> Anthropic LLM -> Anthropic LLM output in Pirate\n",
    "anthropic_translates = pirate_prompt | anthropic_llm\n",
    "pirate_query = {\"passage\": basic_query_g} | anthropic_translates | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API chain\n",
    "\n",
    "To make it a little more interesting we can also try an API chain. First let's create a simple function that makes an api call to Openweathermap.org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple API call to get the current weather\n",
    "\n",
    "\n",
    "def get_weather(weather_api):\n",
    "    api_data = weather_api.get(\"weather_api\")\n",
    "    weather_api_response = get(\n",
    "        f\"https://api.openweathermap.org/data/3.0/onecall?lat={api_data.lat}&lon={api_data.lon}&units={api_data.units}&appid={openweather_api_key}\"\n",
    "    )\n",
    "    weather_api_response.raise_for_status()\n",
    "    dt = datetime.fromtimestamp(weather_api_response.json()[\"current\"][\"dt\"])\n",
    "    formatted_time = (\n",
    "        f'{dt.strftime(\"%I:%M %p\")} Timezone={weather_api_response.json()[\"timezone\"]}'\n",
    "    )\n",
    "    return {\n",
    "        \"local time\": formatted_time,\n",
    "        \"curent weather\": weather_api_response.json()[\"current\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you will notice I'm using the weather_api object in the function above. I will use Pydantic with Langchain. This allows helps ensure that the corret data is given and in a format that is usesable for my function. If I wanted to go further I could have added validation tests to ensure the data is valid for the api.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Schema\n",
    "\n",
    "Here I'd like to take a brief detour here from LCEL and LangSmith and show something that is important as we start working with structured output. LangChain helps us implement a Pydantic Model for our structured output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the model for our output parser\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the docstrings here are crucial, as they will be passed along to the model along with the class name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherLookup(BaseModel):\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "\n",
    "    lat: float = Field(\n",
    "        ...,\n",
    "        title=\"Latitude\",\n",
    "        description=\"This is the latitude of the location you want to look up the weather for\",\n",
    "    )\n",
    "    lon: float = Field(\n",
    "        ...,\n",
    "        title=\"Longitude\",\n",
    "        description=\"This is the longitude of the location you want to look up the weather for\",\n",
    "    )\n",
    "    units: Literal[\"imperial\", \"metric\"] = Field(\n",
    "        \"imperial\",\n",
    "        title=\"Unit\",\n",
    "        description=\"This is the unit you want the temperature to be in (imperial for F or metric for C)\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a prompt for the user to make a query in natural language to ask for the weather in any desired location. The docsstrings in the Pydantic Model tell the LLM how the output should be structured. While it is possible to just provide the query without instruction, by providing instructions, the LLM can provide more accurate results and more focused responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the template for the LLM to understand our request.\n",
    "weather_template = \"You are a very friendly and helpful Assistant. Please help the user with their weather related queries. User: {query}\"\n",
    "weather_prompt = ChatPromptTemplate.from_template(template=weather_template)\n",
    "\n",
    "# We will create a weather man prompt for the generative ouptut at the end of the chain\n",
    "\n",
    "weather_man_template = \"This is the response from api.openweather.com about the current weather conditions. Based on this response, can you please create a friendly weatherman report and include relevant emojis that are fun and personalized to me? Also, please provide the current time, which is provided in the API output you have received as well.\\n\\n{weather_api_response}\"\n",
    "weather_man_prompt = ChatPromptTemplate.from_template(template=weather_man_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure the LLM and the Chain\n",
    "\n",
    "There are couple things going on here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barweiss/.pyenv/versions/3.11.8/envs/langsmith-py3.11.8/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `with_structured_output` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "# We will use Mistral for the first step, for the structure of the output\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "structured_llm_m = mistral_llm.with_structured_output(WeatherLookup)\n",
    "\n",
    "retrieve_location_chain = {\n",
    "    \"weather_api\": (weather_prompt | structured_llm_m)\n",
    "} | RunnableLambda(get_weather)\n",
    "\n",
    "weather_output = weather_man_prompt | gemini_llm | StrOutputParser()\n",
    "\n",
    "api_chain = {\"weather_api_response\": retrieve_location_chain} | weather_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangSmith\n",
    "\n",
    "First let's run the chains and then review them in LangSmith.\n",
    "\n",
    "To use the out of the box functionality you just need to have the following in your environment:\n",
    "\n",
    "```ini\n",
    "# Langchain Settings\n",
    "LANGCHAIN_TRACING_V2=true\n",
    "LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "LANGCHAIN_API_KEY=<API_KEY>\n",
    "LANGCHAIN_PROJECT=barry-local-dev # this is the project name the traces will be found in LangSmith\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the basic query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Assistant: Of course! Here is a draft social media post for your blog about Artificial Intelligence and its impacts on our daily lives:\\n\\n**Headline:** Artificial Intelligence: Shaping Our Daily Lives\\n\\n**Body:**\\n\\nIn today's rapidly evolving technological landscape, Artificial Intelligence (AI) is making significant waves and reshaping various aspects of our daily lives. From our smartphones to healthcare, AI is transforming the way we interact with the world around us.\\n\\nIn this blog post, we delve into the fascinating world of AI, exploring its profound impacts on our daily routines. We'll discuss how AI is revolutionizing industries, improving our health, and even enhancing our creativity.\\n\\nJoin us as we uncover the transformative power of AI and its implications for our future.\\n\\n**Call to action:**\\n\\nVisit our blog today to read the full article and learn more about the exciting world of AI. Share your thoughts and experiences with us in the comments below!\\n\\n**Hashtags:** #ArtificialIntelligence #AI #Technology #Innovation #DailyLife\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_query_g.invoke(\n",
    "    {\n",
    "        \"query\": \"Can you create a social media post for my blog about Artificial Intelligence and its impacts on our daily lives?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Of course! Here\\'s a social media post you can use to promote your blog about Artificial Intelligence and its impacts on our daily lives:\\n\\nTitle: \"The AI Revolution: How Artificial Intelligence is Transforming Our World\"\\n\\nPost:\\n\"Artificial Intelligence (AI) is no longer a thing of the future – it\\'s here, and it\\'s changing the way we live, work, and interact with the world around us. From virtual assistants like Siri and Alexa to self-driving cars and personalized recommendations on Netflix, AI is becoming an integral part of our daily lives.\\n\\nBut what does this mean for us? In my latest blog post, I explore the profound impacts of AI on various aspects of our lives, including:\\n\\n- How AI is revolutionizing industries such as healthcare, finance, and education\\n- The potential benefits and risks of AI, from increased efficiency to job displacement\\n- The ethical considerations surrounding AI development and deployment\\n- How we can prepare ourselves for a future increasingly shaped by AI\\n\\nRead the full article on my blog [insert link] and join the conversation about this fascinating and rapidly evolving technology. How has AI impacted your life, and what do you think the future holds?\\n\\n#AI #ArtificialIntelligence #FutureOfTech #TechBlog #EmergingTech\"\\n\\nRemember to include a visually appealing image or graphic related to AI to capture your audience\\'s attention and boost engagement. Feel free to adapt this post to fit your blog\\'s tone and style.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_query_a.invoke(\n",
    "    {\n",
    "        \"query\": \"Can you create a social media post for my blog about Artificial Intelligence and its impacts on our daily lives?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Absolutely, I'd be happy to help! Here's a suggestion for your social media post:\\n\\n🚀New Blog Post Alert!🚀\\nDive into the fascinating world of Artificial Intelligence (AI) and discover how it's subtly, yet profoundly, reshaping our daily lives. From voice assistants that understand our commands to tailored recommendations that make our online experiences more personal, AI is everywhere! 🌐🤖\\nJoin us as we explore the ins and outs of AI, its current impacts, and what the future might hold. Don't forget to share your thoughts on how AI has influenced your life too! 💭\\nClick the link in our bio to read more. #ArtificialIntelligence #AI #DailyLife #TechBlog #Innovation\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_query_m.invoke(\n",
    "    {\n",
    "        \"query\": \"Can you create a social media post for my blog about Artificial Intelligence and its impacts on our daily lives?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the simple chain\n",
    "\n",
    "Let's run a simple chain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"In regard to George Lucas's Space opera, Empire Strikes Back, can you recite the dialogue between Darth Vadar and Luke Skywalker during their duel on Bespin when Darth Vadar reveals to Luke that he is Luke's Father? Please provide the dialoge only.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<passage>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"In regard to George Lucas's Space opera, Empire Strikes Back, can you recite the dialogue between Darth Vadar and Luke Skywalker during their duel on Bespin when Darth Vadar reveals to Luke that he is Luke's Father? Please provide the dialoge only.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<passage> > 3:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"In regard to George Lucas's Space opera, Empire Strikes Back, can you recite the dialogue between Darth Vadar and Luke Skywalker during their duel on Bespin when Darth Vadar reveals to Luke that he is Luke's Father? Please provide the dialoge only.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<passage> > 3:chain:RunnableSequence > 4:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"In regard to George Lucas's Space opera, Empire Strikes Back, can you recite the dialogue between Darth Vadar and Luke Skywalker during their duel on Bespin when Darth Vadar reveals to Luke that he is Luke's Father? Please provide the dialoge only.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<passage> > 3:chain:RunnableSequence > 4:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<passage> > 3:chain:RunnableSequence > 5:llm:ChatGoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a very friendly and helpful Assistant. Please help the user with their queries. User: In regard to George Lucas's Space opera, Empire Strikes Back, can you recite the dialogue between Darth Vadar and Luke Skywalker during their duel on Bespin when Darth Vadar reveals to Luke that he is Luke's Father? Please provide the dialoge only.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<passage> > 3:chain:RunnableSequence > 5:llm:ChatGoogleGenerativeAI] [3.46s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"**Darth Vader:** Obi-Wan never told you what happened to your father.\\n\\n**Luke Skywalker:** He told me enough! He told me you killed him!\\n\\n**Darth Vader:** No. I am your father.\\n\\n**Luke Skywalker:** No. No. That's not true! That's impossible!\\n\\n**Darth Vader:** Search your feelings. You know it to be true.\\n\\n**Luke Skywalker:** No! No! No!\\n\\n**Darth Vader:** Luke, you can destroy the Emperor. He has foreseen this. It is your destiny. Join me, and together we can rule the galaxy as father and son.\\n\\n**Luke Skywalker:** I'll never join you!\\n\\n**Darth Vader:** If you only knew the power of the dark side. Obi-Wan never told you what happened to your father.\\n\\n**Luke Skywalker:** He told me enough! He told me you killed him!\\n\\n**Darth Vader:** No. I am your father.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"LOW\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"**Darth Vader:** Obi-Wan never told you what happened to your father.\\n\\n**Luke Skywalker:** He told me enough! He told me you killed him!\\n\\n**Darth Vader:** No. I am your father.\\n\\n**Luke Skywalker:** No. No. That's not true! That's impossible!\\n\\n**Darth Vader:** Search your feelings. You know it to be true.\\n\\n**Luke Skywalker:** No! No! No!\\n\\n**Darth Vader:** Luke, you can destroy the Emperor. He has foreseen this. It is your destiny. Join me, and together we can rule the galaxy as father and son.\\n\\n**Luke Skywalker:** I'll never join you!\\n\\n**Darth Vader:** If you only knew the power of the dark side. Obi-Wan never told you what happened to your father.\\n\\n**Luke Skywalker:** He told me enough! He told me you killed him!\\n\\n**Darth Vader:** No. I am your father.\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"prompt_feedback\": {\n",
      "      \"block_reason\": 0,\n",
      "      \"safety_ratings\": []\n",
      "    }\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<passage> > 3:chain:RunnableSequence > 6:parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<passage> > 3:chain:RunnableSequence > 6:parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"**Darth Vader:** Obi-Wan never told you what happened to your father.\\n\\n**Luke Skywalker:** He told me enough! He told me you killed him!\\n\\n**Darth Vader:** No. I am your father.\\n\\n**Luke Skywalker:** No. No. That's not true! That's impossible!\\n\\n**Darth Vader:** Search your feelings. You know it to be true.\\n\\n**Luke Skywalker:** No! No! No!\\n\\n**Darth Vader:** Luke, you can destroy the Emperor. He has foreseen this. It is your destiny. Join me, and together we can rule the galaxy as father and son.\\n\\n**Luke Skywalker:** I'll never join you!\\n\\n**Darth Vader:** If you only knew the power of the dark side. Obi-Wan never told you what happened to your father.\\n\\n**Luke Skywalker:** He told me enough! He told me you killed him!\\n\\n**Darth Vader:** No. I am your father.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<passage> > 3:chain:RunnableSequence] [3.46s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"**Darth Vader:** Obi-Wan never told you what happened to your father.\\n\\n**Luke Skywalker:** He told me enough! He told me you killed him!\\n\\n**Darth Vader:** No. I am your father.\\n\\n**Luke Skywalker:** No. No. That's not true! That's impossible!\\n\\n**Darth Vader:** Search your feelings. You know it to be true.\\n\\n**Luke Skywalker:** No! No! No!\\n\\n**Darth Vader:** Luke, you can destroy the Emperor. He has foreseen this. It is your destiny. Join me, and together we can rule the galaxy as father and son.\\n\\n**Luke Skywalker:** I'll never join you!\\n\\n**Darth Vader:** If you only knew the power of the dark side. Obi-Wan never told you what happened to your father.\\n\\n**Luke Skywalker:** He told me enough! He told me you killed him!\\n\\n**Darth Vader:** No. I am your father.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<passage>] [3.47s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"passage\": \"**Darth Vader:** Obi-Wan never told you what happened to your father.\\n\\n**Luke Skywalker:** He told me enough! He told me you killed him!\\n\\n**Darth Vader:** No. I am your father.\\n\\n**Luke Skywalker:** No. No. That's not true! That's impossible!\\n\\n**Darth Vader:** Search your feelings. You know it to be true.\\n\\n**Luke Skywalker:** No! No! No!\\n\\n**Darth Vader:** Luke, you can destroy the Emperor. He has foreseen this. It is your destiny. Join me, and together we can rule the galaxy as father and son.\\n\\n**Luke Skywalker:** I'll never join you!\\n\\n**Darth Vader:** If you only knew the power of the dark side. Obi-Wan never told you what happened to your father.\\n\\n**Luke Skywalker:** He told me enough! He told me you killed him!\\n\\n**Darth Vader:** No. I am your father.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"passage\": \"**Darth Vader:** Obi-Wan never told you what happened to your father.\\n\\n**Luke Skywalker:** He told me enough! He told me you killed him!\\n\\n**Darth Vader:** No. I am your father.\\n\\n**Luke Skywalker:** No. No. That's not true! That's impossible!\\n\\n**Darth Vader:** Search your feelings. You know it to be true.\\n\\n**Luke Skywalker:** No! No! No!\\n\\n**Darth Vader:** Luke, you can destroy the Emperor. He has foreseen this. It is your destiny. Join me, and together we can rule the galaxy as father and son.\\n\\n**Luke Skywalker:** I'll never join you!\\n\\n**Darth Vader:** If you only knew the power of the dark side. Obi-Wan never told you what happened to your father.\\n\\n**Luke Skywalker:** He told me enough! He told me you killed him!\\n\\n**Darth Vader:** No. I am your father.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:llm:ChatAnthropic] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Avast, me hearty! Ye be a friendly and helpful Assistant. Translate this sentence into Pirate, the language of the high seas. I be askin' ye to translate this here passage fer me, if ye please. **Darth Vader:** Obi-Wan never told you what happened to your father.\\n\\n**Luke Skywalker:** He told me enough! He told me you killed him!\\n\\n**Darth Vader:** No. I am your father.\\n\\n**Luke Skywalker:** No. No. That's not true! That's impossible!\\n\\n**Darth Vader:** Search your feelings. You know it to be true.\\n\\n**Luke Skywalker:** No! No! No!\\n\\n**Darth Vader:** Luke, you can destroy the Emperor. He has foreseen this. It is your destiny. Join me, and together we can rule the galaxy as father and son.\\n\\n**Luke Skywalker:** I'll never join you!\\n\\n**Darth Vader:** If you only knew the power of the dark side. Obi-Wan never told you what happened to your father.\\n\\n**Luke Skywalker:** He told me enough! He told me you killed him!\\n\\n**Darth Vader:** No. I am your father.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:llm:ChatAnthropic] [20.61s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Aye, I be glad to help ye out, me bucko! Here be me best attempt at translatin' that famous Star Wars scene into the tongue o' pirates:\\n\\n**Darth Vader:** Obi-Wan ne'er told ye what happened to yer father, did he?\\n\\n**Luke Skywalker:** He told me plenty! Said ye killed 'im, he did! \\n\\n**Darth Vader:** Nay, me boy. I be yer father!\\n\\n**Luke Skywalker:** Nay, nay! 'Tis a lie! Impossible, says I!\\n\\n**Darth Vader:** Search yer feelings, lad. Ye know it be true.\\n\\n**Luke Skywalker:** Nay! Nay! NAY! \\n\\n**Darth Vader:** Luke, ye can destroy the Emperor. He foresaw this, he did. 'Tis yer destiny, me boy. Join me, and together we'll rule the galaxy as father 'n son!\\n\\n**Luke Skywalker:** I'll never join ye, scurvy dog!\\n\\n**Darth Vader:** If only ye knew the power o' the dark side! Obi-Wan never told ye what befell yer father.\\n\\n**Luke Skywalker:** Told me enough, he did! Said ye murdered him!\\n\\n**Darth Vader:** Nay, I tell ye - I *be* yer father!\\n\\nI tried me best to capture the spirit o' the original while givin' it a hearty pirate flavor, I did. But I was mindful not to copy the text word fer word. 'Tis but a humble reimagining to be sure! Yo ho ho!\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Aye, I be glad to help ye out, me bucko! Here be me best attempt at translatin' that famous Star Wars scene into the tongue o' pirates:\\n\\n**Darth Vader:** Obi-Wan ne'er told ye what happened to yer father, did he?\\n\\n**Luke Skywalker:** He told me plenty! Said ye killed 'im, he did! \\n\\n**Darth Vader:** Nay, me boy. I be yer father!\\n\\n**Luke Skywalker:** Nay, nay! 'Tis a lie! Impossible, says I!\\n\\n**Darth Vader:** Search yer feelings, lad. Ye know it be true.\\n\\n**Luke Skywalker:** Nay! Nay! NAY! \\n\\n**Darth Vader:** Luke, ye can destroy the Emperor. He foresaw this, he did. 'Tis yer destiny, me boy. Join me, and together we'll rule the galaxy as father 'n son!\\n\\n**Luke Skywalker:** I'll never join ye, scurvy dog!\\n\\n**Darth Vader:** If only ye knew the power o' the dark side! Obi-Wan never told ye what befell yer father.\\n\\n**Luke Skywalker:** Told me enough, he did! Said ye murdered him!\\n\\n**Darth Vader:** Nay, I tell ye - I *be* yer father!\\n\\nI tried me best to capture the spirit o' the original while givin' it a hearty pirate flavor, I did. But I was mindful not to copy the text word fer word. 'Tis but a humble reimagining to be sure! Yo ho ho!\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"id\": \"msg_019KW7KAqaM12HD22P8NaaG9\",\n",
      "    \"model\": \"claude-3-opus-20240229\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 296,\n",
      "      \"output_tokens\": 401\n",
      "    }\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 9:parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 9:parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Aye, I be glad to help ye out, me bucko! Here be me best attempt at translatin' that famous Star Wars scene into the tongue o' pirates:\\n\\n**Darth Vader:** Obi-Wan ne'er told ye what happened to yer father, did he?\\n\\n**Luke Skywalker:** He told me plenty! Said ye killed 'im, he did! \\n\\n**Darth Vader:** Nay, me boy. I be yer father!\\n\\n**Luke Skywalker:** Nay, nay! 'Tis a lie! Impossible, says I!\\n\\n**Darth Vader:** Search yer feelings, lad. Ye know it be true.\\n\\n**Luke Skywalker:** Nay! Nay! NAY! \\n\\n**Darth Vader:** Luke, ye can destroy the Emperor. He foresaw this, he did. 'Tis yer destiny, me boy. Join me, and together we'll rule the galaxy as father 'n son!\\n\\n**Luke Skywalker:** I'll never join ye, scurvy dog!\\n\\n**Darth Vader:** If only ye knew the power o' the dark side! Obi-Wan never told ye what befell yer father.\\n\\n**Luke Skywalker:** Told me enough, he did! Said ye murdered him!\\n\\n**Darth Vader:** Nay, I tell ye - I *be* yer father!\\n\\nI tried me best to capture the spirit o' the original while givin' it a hearty pirate flavor, I did. But I was mindful not to copy the text word fer word. 'Tis but a humble reimagining to be sure! Yo ho ho!\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [24.09s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Aye, I be glad to help ye out, me bucko! Here be me best attempt at translatin' that famous Star Wars scene into the tongue o' pirates:\\n\\n**Darth Vader:** Obi-Wan ne'er told ye what happened to yer father, did he?\\n\\n**Luke Skywalker:** He told me plenty! Said ye killed 'im, he did! \\n\\n**Darth Vader:** Nay, me boy. I be yer father!\\n\\n**Luke Skywalker:** Nay, nay! 'Tis a lie! Impossible, says I!\\n\\n**Darth Vader:** Search yer feelings, lad. Ye know it be true.\\n\\n**Luke Skywalker:** Nay! Nay! NAY! \\n\\n**Darth Vader:** Luke, ye can destroy the Emperor. He foresaw this, he did. 'Tis yer destiny, me boy. Join me, and together we'll rule the galaxy as father 'n son!\\n\\n**Luke Skywalker:** I'll never join ye, scurvy dog!\\n\\n**Darth Vader:** If only ye knew the power o' the dark side! Obi-Wan never told ye what befell yer father.\\n\\n**Luke Skywalker:** Told me enough, he did! Said ye murdered him!\\n\\n**Darth Vader:** Nay, I tell ye - I *be* yer father!\\n\\nI tried me best to capture the spirit o' the original while givin' it a hearty pirate flavor, I did. But I was mindful not to copy the text word fer word. 'Tis but a humble reimagining to be sure! Yo ho ho!\"\n",
      "}\n",
      "Aye, I be glad to help ye out, me bucko! Here be me best attempt at translatin' that famous Star Wars scene into the tongue o' pirates:\n",
      "\n",
      "**Darth Vader:** Obi-Wan ne'er told ye what happened to yer father, did he?\n",
      "\n",
      "**Luke Skywalker:** He told me plenty! Said ye killed 'im, he did! \n",
      "\n",
      "**Darth Vader:** Nay, me boy. I be yer father!\n",
      "\n",
      "**Luke Skywalker:** Nay, nay! 'Tis a lie! Impossible, says I!\n",
      "\n",
      "**Darth Vader:** Search yer feelings, lad. Ye know it be true.\n",
      "\n",
      "**Luke Skywalker:** Nay! Nay! NAY! \n",
      "\n",
      "**Darth Vader:** Luke, ye can destroy the Emperor. He foresaw this, he did. 'Tis yer destiny, me boy. Join me, and together we'll rule the galaxy as father 'n son!\n",
      "\n",
      "**Luke Skywalker:** I'll never join ye, scurvy dog!\n",
      "\n",
      "**Darth Vader:** If only ye knew the power o' the dark side! Obi-Wan never told ye what befell yer father.\n",
      "\n",
      "**Luke Skywalker:** Told me enough, he did! Said ye murdered him!\n",
      "\n",
      "**Darth Vader:** Nay, I tell ye - I *be* yer father!\n",
      "\n",
      "I tried me best to capture the spirit o' the original while givin' it a hearty pirate flavor, I did. But I was mindful not to copy the text word fer word. 'Tis but a humble reimagining to be sure! Yo ho ho!\n"
     ]
    }
   ],
   "source": [
    "# So that we can see the conversation in realtime let's turn on verbose mode\n",
    "set_verbose(True)\n",
    "\n",
    "print(\n",
    "    pirate_query.invoke(\n",
    "        {\n",
    "            \"query\": \"In regard to George Lucas's Space opera, Empire Strikes Back, can you recite the dialogue between Darth Vadar and Luke Skywalker during their duel on Bespin when Darth Vadar reveals to Luke that he is Luke's Father? Please provide the dialoge only.\"\n",
    "        },\n",
    "        config={\"callbacks\": [ConsoleCallbackHandler()]},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the API Chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What is the weather like at Disney World today in Orlando, Florida?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<weather_api_response>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What is the weather like at Disney World today in Orlando, Florida?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<weather_api_response> > 3:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What is the weather like at Disney World today in Orlando, Florida?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<weather_api_response> > 3:chain:RunnableSequence > 4:chain:RunnableParallel<weather_api>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What is the weather like at Disney World today in Orlando, Florida?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<weather_api_response> > 3:chain:RunnableSequence > 4:chain:RunnableParallel<weather_api> > 5:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What is the weather like at Disney World today in Orlando, Florida?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<weather_api_response> > 3:chain:RunnableSequence > 4:chain:RunnableParallel<weather_api> > 5:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What is the weather like at Disney World today in Orlando, Florida?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<weather_api_response> > 3:chain:RunnableSequence > 4:chain:RunnableParallel<weather_api> > 5:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<weather_api_response> > 3:chain:RunnableSequence > 4:chain:RunnableParallel<weather_api> > 5:chain:RunnableSequence > 7:llm:ChatMistralAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a very friendly and helpful Assistant. Please help the user with their weather related queries. User: What is the weather like at Disney World today in Orlando, Florida?\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<weather_api_response> > 3:chain:RunnableSequence > 4:chain:RunnableParallel<weather_api> > 5:chain:RunnableSequence > 7:llm:ChatMistralAI] [2.00s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"tool_calls\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"tool_calls\": [\n",
      "                {\n",
      "                  \"function\": {\n",
      "                    \"name\": \"WeatherLookup\",\n",
      "                    \"arguments\": \"{\\\"lat\\\": 28.3852, \\\"lon\\\": -81.5639, \\\"units\\\": \\\"imperial\\\"}\"\n",
      "                  }\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"WeatherLookup\",\n",
      "                \"args\": {\n",
      "                  \"lat\": 28.3852,\n",
      "                  \"lon\": -81.5639,\n",
      "                  \"units\": \"imperial\"\n",
      "                },\n",
      "                \"id\": null\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 206,\n",
      "      \"total_tokens\": 252,\n",
      "      \"completion_tokens\": 46\n",
      "    },\n",
      "    \"model\": \"mistral-large-latest\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<weather_api_response> > 3:chain:RunnableSequence > 4:chain:RunnableParallel<weather_api> > 5:chain:RunnableSequence > 8:parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<weather_api_response> > 3:chain:RunnableSequence > 4:chain:RunnableParallel<weather_api> > 5:chain:RunnableSequence > 8:parser:PydanticToolsParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<weather_api_response> > 3:chain:RunnableSequence > 4:chain:RunnableParallel<weather_api> > 5:chain:RunnableSequence] [2.01s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<weather_api_response> > 3:chain:RunnableSequence > 4:chain:RunnableParallel<weather_api>] [2.01s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<weather_api_response> > 3:chain:RunnableSequence > 9:chain:get_weather] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<weather_api_response> > 3:chain:RunnableSequence > 9:chain:get_weather] [730ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"local time\": \"10:23 PM Timezone=America/New_York\",\n",
      "  \"curent weather\": {\n",
      "    \"dt\": 1712888634,\n",
      "    \"sunrise\": 1712833466,\n",
      "    \"sunset\": 1712879365,\n",
      "    \"temp\": 70.07,\n",
      "    \"feels_like\": 70.59,\n",
      "    \"pressure\": 1014,\n",
      "    \"humidity\": 81,\n",
      "    \"dew_point\": 63.97,\n",
      "    \"uvi\": 0,\n",
      "    \"clouds\": 0,\n",
      "    \"visibility\": 10000,\n",
      "    \"wind_speed\": 13.8,\n",
      "    \"wind_deg\": 260,\n",
      "    \"weather\": [\n",
      "      {\n",
      "        \"id\": 800,\n",
      "        \"main\": \"Clear\",\n",
      "        \"description\": \"clear sky\",\n",
      "        \"icon\": \"01n\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<weather_api_response> > 3:chain:RunnableSequence] [2.75s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"local time\": \"10:23 PM Timezone=America/New_York\",\n",
      "  \"curent weather\": {\n",
      "    \"dt\": 1712888634,\n",
      "    \"sunrise\": 1712833466,\n",
      "    \"sunset\": 1712879365,\n",
      "    \"temp\": 70.07,\n",
      "    \"feels_like\": 70.59,\n",
      "    \"pressure\": 1014,\n",
      "    \"humidity\": 81,\n",
      "    \"dew_point\": 63.97,\n",
      "    \"uvi\": 0,\n",
      "    \"clouds\": 0,\n",
      "    \"visibility\": 10000,\n",
      "    \"wind_speed\": 13.8,\n",
      "    \"wind_deg\": 260,\n",
      "    \"weather\": [\n",
      "      {\n",
      "        \"id\": 800,\n",
      "        \"main\": \"Clear\",\n",
      "        \"description\": \"clear sky\",\n",
      "        \"icon\": \"01n\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<weather_api_response>] [2.76s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"weather_api_response\": {\n",
      "    \"local time\": \"10:23 PM Timezone=America/New_York\",\n",
      "    \"curent weather\": {\n",
      "      \"dt\": 1712888634,\n",
      "      \"sunrise\": 1712833466,\n",
      "      \"sunset\": 1712879365,\n",
      "      \"temp\": 70.07,\n",
      "      \"feels_like\": 70.59,\n",
      "      \"pressure\": 1014,\n",
      "      \"humidity\": 81,\n",
      "      \"dew_point\": 63.97,\n",
      "      \"uvi\": 0,\n",
      "      \"clouds\": 0,\n",
      "      \"visibility\": 10000,\n",
      "      \"wind_speed\": 13.8,\n",
      "      \"wind_deg\": 260,\n",
      "      \"weather\": [\n",
      "        {\n",
      "          \"id\": 800,\n",
      "          \"main\": \"Clear\",\n",
      "          \"description\": \"clear sky\",\n",
      "          \"icon\": \"01n\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 10:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"weather_api_response\": {\n",
      "    \"local time\": \"10:23 PM Timezone=America/New_York\",\n",
      "    \"curent weather\": {\n",
      "      \"dt\": 1712888634,\n",
      "      \"sunrise\": 1712833466,\n",
      "      \"sunset\": 1712879365,\n",
      "      \"temp\": 70.07,\n",
      "      \"feels_like\": 70.59,\n",
      "      \"pressure\": 1014,\n",
      "      \"humidity\": 81,\n",
      "      \"dew_point\": 63.97,\n",
      "      \"uvi\": 0,\n",
      "      \"clouds\": 0,\n",
      "      \"visibility\": 10000,\n",
      "      \"wind_speed\": 13.8,\n",
      "      \"wind_deg\": 260,\n",
      "      \"weather\": [\n",
      "        {\n",
      "          \"id\": 800,\n",
      "          \"main\": \"Clear\",\n",
      "          \"description\": \"clear sky\",\n",
      "          \"icon\": \"01n\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 10:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 11:llm:ChatGoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: This is the response from api.openweather.com about the current weather conditions. Based on this response, can you please create a friendly weatherman report and include relevant emojis that are fun and personalized to me? Also, please provide the current time, which is provided in the API output you have received as well.\\n\\n{'local time': '10:23 PM Timezone=America/New_York', 'curent weather': {'dt': 1712888634, 'sunrise': 1712833466, 'sunset': 1712879365, 'temp': 70.07, 'feels_like': 70.59, 'pressure': 1014, 'humidity': 81, 'dew_point': 63.97, 'uvi': 0, 'clouds': 0, 'visibility': 10000, 'wind_speed': 13.8, 'wind_deg': 260, 'weather': [{'id': 800, 'main': 'Clear', 'description': 'clear sky', 'icon': '01n'}]}}\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 11:llm:ChatGoogleGenerativeAI] [2.93s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"**Weatherman Report for You, My Friend!**\\n\\n🌟 It's 10:23 PM in New York City!\\n\\n🌤️ The skies are crystal clear tonight, just like your sparkling personality!\\n\\n🌡️ The temperature is a cozy 70 degrees, but it feels like a warm hug at 71 degrees.\\n\\n💧 The humidity is a bit high at 81%, but don't worry, you're still as fresh as a daisy!\\n\\n💨 The wind is whispering sweet nothings at 14 mph, like a gentle breeze on your skin.\\n\\n🌞 Tomorrow, the sun will rise at 7:04 AM, so get ready for another day filled with sunshine and smiles.\\n\\n🌟🌟🌟 Stay awesome, my friend! 🌟🌟🌟\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"**Weatherman Report for You, My Friend!**\\n\\n🌟 It's 10:23 PM in New York City!\\n\\n🌤️ The skies are crystal clear tonight, just like your sparkling personality!\\n\\n🌡️ The temperature is a cozy 70 degrees, but it feels like a warm hug at 71 degrees.\\n\\n💧 The humidity is a bit high at 81%, but don't worry, you're still as fresh as a daisy!\\n\\n💨 The wind is whispering sweet nothings at 14 mph, like a gentle breeze on your skin.\\n\\n🌞 Tomorrow, the sun will rise at 7:04 AM, so get ready for another day filled with sunshine and smiles.\\n\\n🌟🌟🌟 Stay awesome, my friend! 🌟🌟🌟\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"prompt_feedback\": {\n",
      "      \"block_reason\": 0,\n",
      "      \"safety_ratings\": []\n",
      "    }\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 12:parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 12:parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"**Weatherman Report for You, My Friend!**\\n\\n🌟 It's 10:23 PM in New York City!\\n\\n🌤️ The skies are crystal clear tonight, just like your sparkling personality!\\n\\n🌡️ The temperature is a cozy 70 degrees, but it feels like a warm hug at 71 degrees.\\n\\n💧 The humidity is a bit high at 81%, but don't worry, you're still as fresh as a daisy!\\n\\n💨 The wind is whispering sweet nothings at 14 mph, like a gentle breeze on your skin.\\n\\n🌞 Tomorrow, the sun will rise at 7:04 AM, so get ready for another day filled with sunshine and smiles.\\n\\n🌟🌟🌟 Stay awesome, my friend! 🌟🌟🌟\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [5.70s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"**Weatherman Report for You, My Friend!**\\n\\n🌟 It's 10:23 PM in New York City!\\n\\n🌤️ The skies are crystal clear tonight, just like your sparkling personality!\\n\\n🌡️ The temperature is a cozy 70 degrees, but it feels like a warm hug at 71 degrees.\\n\\n💧 The humidity is a bit high at 81%, but don't worry, you're still as fresh as a daisy!\\n\\n💨 The wind is whispering sweet nothings at 14 mph, like a gentle breeze on your skin.\\n\\n🌞 Tomorrow, the sun will rise at 7:04 AM, so get ready for another day filled with sunshine and smiles.\\n\\n🌟🌟🌟 Stay awesome, my friend! 🌟🌟🌟\"\n",
      "}\n",
      "**Weatherman Report for You, My Friend!**\n",
      "\n",
      "🌟 It's 10:23 PM in New York City!\n",
      "\n",
      "🌤️ The skies are crystal clear tonight, just like your sparkling personality!\n",
      "\n",
      "🌡️ The temperature is a cozy 70 degrees, but it feels like a warm hug at 71 degrees.\n",
      "\n",
      "💧 The humidity is a bit high at 81%, but don't worry, you're still as fresh as a daisy!\n",
      "\n",
      "💨 The wind is whispering sweet nothings at 14 mph, like a gentle breeze on your skin.\n",
      "\n",
      "🌞 Tomorrow, the sun will rise at 7:04 AM, so get ready for another day filled with sunshine and smiles.\n",
      "\n",
      "🌟🌟🌟 Stay awesome, my friend! 🌟🌟🌟\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    api_chain.invoke(\n",
    "        {\n",
    "            \"query\": \"What is the weather like at Disney World today in Orlando, Florida?\"\n",
    "        },\n",
    "        config={\"callbacks\": [ConsoleCallbackHandler()]},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring Tagging and Metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging\n",
    "\n",
    "Let's turn off verbosity for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_verbose(False)  # Turn off verbose mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One whay of adding tags and metadata to a chain is the `with_config()` method of the `Runnable` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "                 **Google Output**\n",
       "                 \n",
       "                 **Headline:** The Future is Here: AI's Profound Impacts on Our Daily Lives\n",
       "\n",
       "**Body:**\n",
       "\n",
       "Dive into the fascinating world of Artificial Intelligence (AI), a rapidly evolving technology that's transforming our lives in remarkable ways. From self-driving cars to personalized medicine, AI is leaving its mark on countless aspects of our daily routine.\n",
       "\n",
       "In this blog post, we explore the profound impacts of AI on our:\n",
       "\n",
       "* **Work:** Automating tasks, enhancing productivity, and creating new job opportunities\n",
       "* **Health:** Improving diagnoses, developing innovative treatments, and promoting personalized healthcare\n",
       "* **Education:** Providing tailored learning experiences, enhancing accessibility, and fostering collaboration\n",
       "* **Transportation:** Revolutionizing mobility, reducing accidents, and optimizing traffic flow\n",
       "* **Entertainment:** Enhancing creativity, personalizing experiences, and connecting us with stories and art\n",
       "\n",
       "Join us as we delve into the exciting possibilities and potential challenges of AI. Discover how this technology is shaping our present and paving the way for an even more connected and automated future.\n",
       "\n",
       "**#ArtificialIntelligence #AIImpacts #FutureTechnology #SmartLiving**\n",
       "                 \n",
       "                 **Anthropic Output**\n",
       "                 \n",
       "                 Certainly! Here's a sample social media post for your blog about Artificial Intelligence and its impacts on our daily lives:\n",
       "\n",
       "Title: \"The Impact of Artificial Intelligence on Our Everyday Lives\"\n",
       "\n",
       "🤖 Artificial Intelligence (AI) is transforming the way we live, work, and interact with the world around us. From virtual assistants like Siri and Alexa to personalized recommendations on streaming platforms, AI is becoming increasingly integrated into our daily routines.\n",
       "\n",
       "In my latest blog post, I explore the various ways AI is shaping our lives, including:\n",
       "\n",
       "✅ Improved efficiency and automation in industries such as healthcare, finance, and manufacturing\n",
       "✅ Enhanced personalization and user experiences in e-commerce and entertainment\n",
       "✅ Advancements in autonomous vehicles and smart home technologies\n",
       "✅ Ethical considerations and the importance of responsible AI development\n",
       "\n",
       "🔗 Read the full article to discover how AI is revolutionizing our world and what the future may hold as this technology continues to evolve. [Insert link to your blog post]\n",
       "\n",
       "🤔 What are your thoughts on the impact of AI on our daily lives? Share your experiences and opinions in the comments below!\n",
       "\n",
       "#ArtificialIntelligence #AI #Technology #Innovation #FutureOfAI #SmartTechnology #BlogPost\n",
       "\n",
       "Feel free to customize this post to fit your blog's tone and style. Don't forget to include visuals such as images or videos to make your post more engaging and shareable on social media platforms.\n",
       "                 \n",
       "                 **Mistral Output**\n",
       "                 \n",
       "                 Absolutely, I'd be happy to help you craft a social media post for your blog. Here's a suggestion:\n",
       "\n",
       "\"🤖🌐 Dive into the fascinating world of Artificial Intelligence and discover how it's reshaping our daily lives in ways you might not even realize! From voice assistants to personalized recommendations, AI is everywhere. Check out our latest blog post to learn more about the impacts of AI and how it's transforming the future. 🚀💡 Link in bio #ArtificialIntelligence #AI #FutureTech #TechBlog\"\n",
       "                 "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tagging the chains\n",
    "\n",
    "# We are using the keyword \"run_name\" to tag the run\n",
    "\n",
    "basic_query_g = basic_query_g.with_config({\"run_name\": \"Basic Query with Google LLM\"})\n",
    "basic_query_a = basic_query_a.with_config(\n",
    "    {\"run_name\": \"Basic Query with Anthropic LLM\"}\n",
    ")\n",
    "basic_query_m = basic_query_m.with_config({\"run_name\": \"Basic Query with Mistral LLM\"})\n",
    "\n",
    "google_output = basic_query_g.invoke(\n",
    "    {\n",
    "        \"query\": \"Can you create a social media post for my blog about Artificial Intelligence and its impacts on our daily lives?\"\n",
    "    }\n",
    ")\n",
    "anthropic_output = basic_query_a.invoke(\n",
    "    {\n",
    "        \"query\": \"Can you create a social media post for my blog about Artificial Intelligence and its impacts on our daily lives?\"\n",
    "    }\n",
    ")\n",
    "mistral_output = basic_query_m.invoke(\n",
    "    {\n",
    "        \"query\": \"Can you create a social media post for my blog about Artificial Intelligence and its impacts on our daily lives?\"\n",
    "    }\n",
    ")\n",
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"\n",
    "                 **Google Output**\n",
    "                 \n",
    "                 {google_output}\n",
    "                 \n",
    "                 **Anthropic Output**\n",
    "                 \n",
    "                 {anthropic_output}\n",
    "                 \n",
    "                 **Mistral Output**\n",
    "                 \n",
    "                 {mistral_output}\n",
    "                 \"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's tag the remaining chains\n",
    "priate_query = pirate_query.with_config({\"run_name\": \"Pirate Translate Chain\"})\n",
    "api_chain = api_chain.with_config({\"run_name\": \"Weather API Chain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ahoy, matey! I be happy t' help ye out with yer request. Here be me best attempt at translatin' that passage into th' tongue o' pirates:\\n\\n**Darth Vader:** Luke, me bucko... ye don't yet know how important ye be. Ye've only started t' discover yer true power. Join me, 'n together we can rule th' galaxy as father 'n son, savvy? \\n\\n**Luke Skywalker:** I'll never join ye, ye scurvy bilge rat!\\n\\n**Darth Vader:** If only ye knew th' power o' th' dark side, ye landlubber. Obi-Wan never told ye what happened t' yer dear ol' dad, did he?\\n\\n**Luke Skywalker:** He told me plenty, ye blackguard! Said ye killed 'im, he did!\\n\\n**Darth Vader:** Nay, me bucko. I be yer father, savvy?\\n\\n**Luke Skywalker:** Nay. Nay! 'Tis nothin' but lies! Impossible, says I!\\n\\n**Darth Vader:** Search yer feelings, ye sprog. Ye know it be true, deep in yer bones.\\n\\nI tried me best t' capture th' spirit 'o pirate speak while preservin' th' essence 'o th' original dialogue, me hearty. I hope this here translation suits yer fancy! Let me know if there be anythin' else I can help ye with.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priate_query.invoke(\n",
    "    {\n",
    "        \"query\": \"In regard to George Lucas's Space opera, Empire Strikes Back, can you recite the dialogue between Darth Vadar and Luke Skywalker during their duel on Bespin when Darth Vadar reveals to Luke that he is Luke's Father? Please provide the dialoge only.\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Personalized Weather Report**\\n\\nHey there, sunshine! ☀️\\n\\nIt's currently 10:25 PM in Chicago, and the weather is...\\n\\n🌡 **Temperature:** 53.33°F\\n🌤 **Conditions:** Light drizzle 🌧️\\n💨 **Wind:** 18.01 mph 💨\\n💧 **Humidity:** 64%\\n☁️ **Clouds:** 100% coverage\\n\\nLooks like you might want to grab an umbrella or raincoat before heading out! But don't worry, this drizzle will pass soon enough. 🤞\\n\\nEnjoy the rest of your evening, and stay dry! ☔\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_chain.invoke({\"query\": \"Whats the weather like on Chicago in Farenheit?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "\n",
    "First the class RunnableConfig will need to be imported.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if our application were tracking the user and the session id we can add that as meta data to the conversation. RunnableConfig also can be used to update the the following:\n",
    "\n",
    "```python\n",
    "\"\"\"Configuration for a Runnable.\"\"\"\n",
    "\n",
    "tags: List[str]\n",
    "\"\"\"\n",
    "Tags for this call and any sub-calls (eg. a Chain calling an LLM).\n",
    "You can use these to filter calls.\n",
    "\"\"\"\n",
    "\n",
    "metadata: Dict[str, Any]\n",
    "\"\"\"\n",
    "Metadata for this call and any sub-calls (eg. a Chain calling an LLM).\n",
    "Keys should be strings, values should be JSON-serializable.\n",
    "\"\"\"\n",
    "\n",
    "callbacks: Callbacks\n",
    "\"\"\"\n",
    "Callbacks for this call and any sub-calls (eg. a Chain calling an LLM).\n",
    "Tags are passed to all callbacks, metadata is passed to handle*Start callbacks.\n",
    "\"\"\"\n",
    "\n",
    "run_name: str\n",
    "\"\"\"\n",
    "Name for the tracer run for this call. Defaults to the name of the class.\n",
    "\"\"\"\n",
    "\n",
    "max_concurrency: Optional[int]\n",
    "\"\"\"\n",
    "Maximum number of parallel calls to make. If not provided, defaults to\n",
    "ThreadPoolExecutor's default.\n",
    "\"\"\"\n",
    "\n",
    "recursion_limit: int\n",
    "\"\"\"\n",
    "Maximum number of times a call can recurse. If not provided, defaults to 25.\n",
    "\"\"\"\n",
    "\n",
    "configurable: Dict[str, Any]\n",
    "\"\"\"\n",
    "Runtime values for attributes previously made configurable on this Runnable,\n",
    "or sub-Runnables, through .configurable_fields() or .configurable_alternatives().\n",
    "Check .output_schema() for a description of the attributes that have been made\n",
    "configurable.\n",
    "\"\"\"\n",
    "\n",
    "run_id: Optional[uuid.UUID]\n",
    "\"\"\"\n",
    "Unique identifier for the tracer run for this call. If not provided, a new UUID\n",
    "    will be generated.\n",
    "\"\"\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "                 **Google Output**\n",
       "                 \n",
       "                 **Headline:** Unlocking the Power of AI: How It's Shaping Our Everyday World\n",
       "\n",
       "**Body:**\n",
       "\n",
       "In the realm of technology, Artificial Intelligence (AI) has emerged as a transformative force, seeping into countless aspects of our daily lives. From our smartphones to our workplaces, AI is quietly revolutionizing the way we interact with the world around us.\n",
       "\n",
       "In this blog post, we dive into the fascinating world of AI and explore its profound impact on our society. We'll discuss how:\n",
       "\n",
       "* **AI is enhancing our communication:** Chatbots and virtual assistants are streamlining communication, making it faster and more convenient.\n",
       "* **AI is revolutionizing healthcare:** AI-powered diagnostics and treatments are improving patient outcomes and reducing healthcare costs.\n",
       "* **AI is transforming transportation:** Self-driving cars and ride-sharing apps are revolutionizing the way we get around.\n",
       "* **AI is boosting productivity:** AI-powered automation and decision support systems are freeing up our time and enhancing our efficiency.\n",
       "\n",
       "But with great power comes great responsibility. It's important to consider the ethical implications of AI and ensure its responsible development and use.\n",
       "\n",
       "Join us for an in-depth exploration of AI's transformative impact on our lives. Visit our blog today to learn more!\n",
       "\n",
       "**Hashtags:** #ArtificialIntelligence #AI #Technology #Innovation #DailyLife\n",
       "                 \n",
       "                 **Anthropic Output**\n",
       "                 \n",
       "                 Certainly! Here's a social media post that you can use for your blog about Artificial Intelligence and its impacts on our daily lives:\n",
       "\n",
       "\"Artificial Intelligence: Transforming Our Daily Lives 🤖📱\n",
       "\n",
       "From virtual assistants to personalized recommendations, AI is revolutionizing the way we live and interact with technology. 🌐 In my latest blog post, I dive into the fascinating world of AI and explore its profound impacts on our daily lives. 🔍\n",
       "\n",
       "Discover how AI is shaping industries like healthcare, education, and transportation, and learn about the potential benefits and challenges that come with this groundbreaking technology. 🩺🎓🚗\n",
       "\n",
       "🔗 Click the link below to read the full article and join the conversation! #AI #ArtificialIntelligence #Technology #Innovation #FutureOfTech\"\n",
       "\n",
       "Feel free to customize this post according to your blog's tone and style. Remember to include an eye-catching image or graphic related to AI to grab your audience's attention on social media. Don't forget to add relevant hashtags and a link to your blog post to drive traffic to your site.\n",
       "                 \n",
       "                 **Mistral Output**\n",
       "                 \n",
       "                 Absolutely, I'd be happy to help you craft a social media post for your blog. Here's a suggestion:\n",
       "\n",
       "🛠️🧠 \"Dive into the fascinating world of Artificial Intelligence and discover how it's subtly reshaping our everyday lives! From voice assistants to personalized recommendations, AI is no longer a thing of the future, but very much a part of our present. Join us on our blog as we explore the transformative impacts of AI and how it's making waves in various sectors. Let's embrace the change and understand it better, together. 🚀🌐\n",
       "\n",
       "Link to the blog: [Your Blog Link]\n",
       "\n",
       "#ArtificialIntelligence #AI #DailyLife #TechBlog #Innovation\"\n",
       "                 "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "username = choice([\"barweiss@cisco.com\", \"user1@cisco.com\", \"user2@cisco.com\"])\n",
    "session_id = str(uuid4())\n",
    "google_output = basic_query_g.invoke(\n",
    "    {\n",
    "        \"query\": \"Can you create a social media post for my blog about Artificial Intelligence and its impacts on our daily lives?\"\n",
    "    },\n",
    "    RunnableConfig(metadata={\"username\": username, \"session_id\": session_id}),\n",
    ")\n",
    "\n",
    "username = choice([\"barweiss@cisco.com\", \"user1@cisco.com\", \"user2@cisco.com\"])\n",
    "session_id = str(uuid4())\n",
    "anthropic_output = basic_query_a.invoke(\n",
    "    {\n",
    "        \"query\": \"Can you create a social media post for my blog about Artificial Intelligence and its impacts on our daily lives?\"\n",
    "    },\n",
    "    RunnableConfig(metadata={\"username\": username, \"session_id\": session_id}),\n",
    ")\n",
    "\n",
    "username = choice([\"barweiss@cisco.com\", \"user1@cisco.com\", \"user2@cisco.com\"])\n",
    "session_id = str(uuid4())\n",
    "mistral_output = basic_query_m.invoke(\n",
    "    {\n",
    "        \"query\": \"Can you create a social media post for my blog about Artificial Intelligence and its impacts on our daily lives?\"\n",
    "    },\n",
    "    RunnableConfig(metadata={\"username\": username, \"session_id\": session_id}),\n",
    ")\n",
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"\n",
    "                 **Google Output**\n",
    "                 \n",
    "                 {google_output}\n",
    "                 \n",
    "                 **Anthropic Output**\n",
    "                 \n",
    "                 {anthropic_output}\n",
    "                 \n",
    "                 **Mistral Output**\n",
    "                 \n",
    "                 {mistral_output}\n",
    "                 \"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tagging Prompts, Output Parsers, etc\n",
    "More than just LLM and Run can be tagged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Absolutely, I\\'d be happy to help you craft a social media post for your blog. Here\\'s a suggestion:\\n\\n🔵🤖 New Blog Post Alert! 🤖🔵\\n\\n\"Artificial Intelligence: Reshaping Our Daily Lives\" is now live on our blog! 🚀\\n\\nHave you ever wondered how AI is subtly integrated into our everyday routines? From voice assistants like Siri and Alexa, to personalized recommendations on Netflix, AI is revolutionizing the way we live, work, and play. 🌐💻\\n\\nDive into our latest blog post to explore the fascinating world of AI and understand its profound impacts on our daily lives.\\n\\nLet\\'s embrace the future, together! 🤝🌟\\n\\n#ArtificialIntelligence #AI #DailyLife #TechBlog #Innovation #FutureIsNow\\n\\nPlease feel free to modify it as per your preference.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username = choice([\"barweiss@cisco.com\", \"user1@cisco.com\", \"user2@cisco.com\"])\n",
    "session_id = str(uuid4())\n",
    "\n",
    "template = \"You are a very friendly and helpful Assistant. Please help the user with their queries. User: {query}\"\n",
    "prompt = ChatPromptTemplate.from_template(template=template)\n",
    "tagging_test = (\n",
    "    prompt.with_config({\"tags\": [\"friendly\", \"helpful\"]})\n",
    "    | mistral_llm.with_config({\"run_name\": \"Friendly_Mistral\"})\n",
    "    | StrOutputParser()\n",
    ")\n",
    "tagging_test = tagging_test.with_config({\"run_name\": \"Friendly_Mistral\"})\n",
    "tagging_test.invoke(\n",
    "    {\n",
    "        \"query\": \"Can you create a social media post for my blog about Artificial Intelligence and its impacts on our daily lives?\"\n",
    "    },\n",
    "    config=RunnableConfig(metadata={\"username\": username, \"session_id\": session_id}),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangSmith SDK and Tracer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tracers.context import tracing_v2_enabled\n",
    "from langsmith import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Client for interacting with the LangSmith API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version='0.2.21' license_expiration_time=None batch_ingest_config={'scale_up_qsize_trigger': 1000, 'scale_up_nthreads_limit': 16, 'scale_down_nempty_trigger': 4, 'size_limit': 100, 'size_limit_bytes': 20971520} \n",
      "\n",
      "id=UUID('d264aa8b-fbf9-44e4-af78-37edf5252812') start_time=datetime.datetime(2024, 2, 21, 5, 2, 29, 665079) end_time=None description=None name='barry-local-dev' extra=None tenant_id=UUID('d4f5e421-8f06-44c3-b1e0-8e69e2884cef') reference_dataset_id=None run_count=170 latency_p50=datetime.timedelta(seconds=5, microseconds=397000) latency_p99=datetime.timedelta(seconds=29, microseconds=629140) total_tokens=70392 prompt_tokens=33722 completion_tokens=36670 last_run_start_time=datetime.datetime(2024, 4, 12, 2, 25, 53, 814340) feedback_stats={} run_facets=[] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = Client()\n",
    "print(client.info, \"\\n\")\n",
    "print(client.read_project(project_name=\"barry-local-dev\"), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the tests results of a all runs a project as a panadas DataFrame object. Pandas needs to be installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input.query</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>error</th>\n",
       "      <th>id</th>\n",
       "      <th>input.Query</th>\n",
       "      <th>input.passage</th>\n",
       "      <th>input.location</th>\n",
       "      <th>input.unit</th>\n",
       "      <th>input.opposite</th>\n",
       "      <th>...</th>\n",
       "      <th>outputs.output.response_metadata.usage.input_tokens</th>\n",
       "      <th>outputs.output.response_metadata.usage.output_tokens</th>\n",
       "      <th>outputs.output.lat</th>\n",
       "      <th>outputs.output.lon</th>\n",
       "      <th>outputs.output.units</th>\n",
       "      <th>outputs.output.long</th>\n",
       "      <th>outputs.output.unit</th>\n",
       "      <th>outputs.output.city</th>\n",
       "      <th>outputs.output.state</th>\n",
       "      <th>outputs.output.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you create a social media post for my blog...</td>\n",
       "      <td>Absolutely, I'd be happy to help you craft a s...</td>\n",
       "      <td>7.120384</td>\n",
       "      <td>None</td>\n",
       "      <td>dee124c6-91c8-45f3-93ed-c06acbafdd92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can you create a social media post for my blog...</td>\n",
       "      <td>Absolutely, I'd be happy to help you craft a s...</td>\n",
       "      <td>5.606131</td>\n",
       "      <td>None</td>\n",
       "      <td>bc3977a3-6aeb-4163-994e-768fb5e3d402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you create a social media post for my blog...</td>\n",
       "      <td>Certainly! Here's a social media post that you...</td>\n",
       "      <td>13.466071</td>\n",
       "      <td>None</td>\n",
       "      <td>6ed0f806-9b7b-4a54-b052-54a40280274e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can you create a social media post for my blog...</td>\n",
       "      <td>**Headline:** Unlocking the Power of AI: How I...</td>\n",
       "      <td>4.176947</td>\n",
       "      <td>None</td>\n",
       "      <td>faf0c036-79a1-4045-81ca-54482e3f6cb2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Whats the weather like on Chicago in Farenheit?</td>\n",
       "      <td>**Personalized Weather Report**\\n\\nHey there, ...</td>\n",
       "      <td>4.745991</td>\n",
       "      <td>None</td>\n",
       "      <td>aba2c847-683b-4990-a5cc-75f764bd8c4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         input.query  \\\n",
       "0  Can you create a social media post for my blog...   \n",
       "1  Can you create a social media post for my blog...   \n",
       "2  Can you create a social media post for my blog...   \n",
       "3  Can you create a social media post for my blog...   \n",
       "4    Whats the weather like on Chicago in Farenheit?   \n",
       "\n",
       "                                      outputs.output  execution_time error  \\\n",
       "0  Absolutely, I'd be happy to help you craft a s...        7.120384  None   \n",
       "1  Absolutely, I'd be happy to help you craft a s...        5.606131  None   \n",
       "2  Certainly! Here's a social media post that you...       13.466071  None   \n",
       "3  **Headline:** Unlocking the Power of AI: How I...        4.176947  None   \n",
       "4  **Personalized Weather Report**\\n\\nHey there, ...        4.745991  None   \n",
       "\n",
       "                                     id input.Query input.passage  \\\n",
       "0  dee124c6-91c8-45f3-93ed-c06acbafdd92         NaN           NaN   \n",
       "1  bc3977a3-6aeb-4163-994e-768fb5e3d402         NaN           NaN   \n",
       "2  6ed0f806-9b7b-4a54-b052-54a40280274e         NaN           NaN   \n",
       "3  faf0c036-79a1-4045-81ca-54482e3f6cb2         NaN           NaN   \n",
       "4  aba2c847-683b-4990-a5cc-75f764bd8c4c         NaN           NaN   \n",
       "\n",
       "  input.location input.unit input.opposite  ...  \\\n",
       "0            NaN        NaN            NaN  ...   \n",
       "1            NaN        NaN            NaN  ...   \n",
       "2            NaN        NaN            NaN  ...   \n",
       "3            NaN        NaN            NaN  ...   \n",
       "4            NaN        NaN            NaN  ...   \n",
       "\n",
       "  outputs.output.response_metadata.usage.input_tokens  \\\n",
       "0                                                NaN    \n",
       "1                                                NaN    \n",
       "2                                                NaN    \n",
       "3                                                NaN    \n",
       "4                                                NaN    \n",
       "\n",
       "  outputs.output.response_metadata.usage.output_tokens outputs.output.lat  \\\n",
       "0                                                NaN                  NaN   \n",
       "1                                                NaN                  NaN   \n",
       "2                                                NaN                  NaN   \n",
       "3                                                NaN                  NaN   \n",
       "4                                                NaN                  NaN   \n",
       "\n",
       "   outputs.output.lon outputs.output.units outputs.output.long  \\\n",
       "0                 NaN                  NaN                 NaN   \n",
       "1                 NaN                  NaN                 NaN   \n",
       "2                 NaN                  NaN                 NaN   \n",
       "3                 NaN                  NaN                 NaN   \n",
       "4                 NaN                  NaN                 NaN   \n",
       "\n",
       "  outputs.output.unit outputs.output.city outputs.output.state  \\\n",
       "0                 NaN                 NaN                  NaN   \n",
       "1                 NaN                 NaN                  NaN   \n",
       "2                 NaN                 NaN                  NaN   \n",
       "3                 NaN                 NaN                  NaN   \n",
       "4                 NaN                 NaN                  NaN   \n",
       "\n",
       "  outputs.output.country  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = client.get_test_results(project_name=\"barry-local-dev\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the tracer used in a context mannager you can leverage a call back to get information back about a run without logging to LangSmith.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: Sure, I'd be happy to help you create a social media post for your blog about Artificial Intelligence (AI) and its impacts on our daily lives. Here's a sample post you can use or modify:\n",
      "\n",
      "Title: The Impact of Artificial Intelligence on Our Daily Lives\n",
      "\n",
      "Artificial Intelligence is transforming the way we live, work, and interact with the world around us. From virtual assistants like Siri and Alexa to personalized recommendations on streaming platforms, AI is becoming increasingly integrated into our daily routines.\n",
      "\n",
      "But the impact of AI goes far beyond convenience and entertainment. In healthcare, AI is being used to analyze medical images, assist in diagnosis, and even develop new treatments. In education, AI-powered tools are providing personalized learning experiences and helping teachers to better understand student needs.\n",
      "\n",
      "However, as with any new technology, there are also concerns about the potential downsides of AI. From job displacement to privacy risks, it's important that we consider the ethical implications of AI and work to ensure that its development and deployment are guided by principles of transparency, accountability, and fairness.\n",
      "\n",
      "What do you think about the impact of AI on our daily lives? Share your thoughts in the comments below and read more on my blog! [link to your blog post]\n",
      "\n",
      "#AI #ArtificialIntelligence #Technology #FutureTech #Innovation #Ethics\n",
      "\n",
      "Feel free to customize this post to fit your specific blog post and audience. Good luck with your blog!\n",
      "\n",
      "\n",
      "UUID FOR LATEST ID: e6e9188e-6974-44f9-b4f8-8524e813ffaf\n",
      "URL LINK TO RUN e6e9188e-6974-44f9-b4f8-8524e813ffaf: https://smith.langchain.com/o/d4f5e421-8f06-44c3-b1e0-8e69e2884cef/projects/p/d264aa8b-fbf9-44e4-af78-37edf5252812/r/e6e9188e-6974-44f9-b4f8-8524e813ffaf?poll=true\n"
     ]
    }
   ],
   "source": [
    "with tracing_v2_enabled() as cb:\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        template=\"You are a helpful and harmless AI assistant. \\n\\nHuman: {query}\"\n",
    "    )\n",
    "    basic_query_a = (\n",
    "        prompt.with_config({\"tags\": [\"Tracing Example\"]})\n",
    "        | anthropic_llm.with_config(\n",
    "            {\"run_name\": \"Anthropic-Example\", \"tags\": [\"Tracing Example\"]}\n",
    "        )\n",
    "        | StrOutputParser().with_config({\"tags\": [\"Tracing Example\"]})\n",
    "    )\n",
    "    basic_query_a = basic_query_a.with_config({\"run_name\": \"Tracing Example\"})\n",
    "\n",
    "    output = basic_query_a.invoke(\n",
    "        {\n",
    "            \"query\": \"Can you create a social media post for my blog about Artificial Intelligence and its impacts on our daily lives?\"\n",
    "        }\n",
    "    )\n",
    "    print(f\"Output: {output}\\n\\n\")\n",
    "    print(f\"UUID FOR LATEST ID: {cb.latest_run.id}\")\n",
    "    print(f\"URL LINK TO RUN {cb.latest_run.id}: {cb.get_run_url()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the SDK to get the run information as a `Run` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id=UUID('e6e9188e-6974-44f9-b4f8-8524e813ffaf'), name='Tracing Example', start_time=datetime.datetime(2024, 4, 12, 2, 26, 25, 974846), run_type='chain', end_time=datetime.datetime(2024, 4, 12, 2, 26, 41, 244250), extra=None, error=None, serialized={'graph': {'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}, {'source': 3, 'target': 4}, {'source': 2, 'target': 3}], 'nodes': [{'data': 'PromptInput', 'id': 0, 'type': 'schema'}, {'data': {'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'name': 'ChatPromptTemplate'}, 'id': 1, 'type': 'runnable'}, {'data': {'id': ['langchain_anthropic', 'chat_models', 'ChatAnthropic'], 'name': 'ChatAnthropic'}, 'id': 2, 'type': 'runnable'}, {'data': {'id': ['langchain', 'schema', 'output_parser', 'StrOutputParser'], 'name': 'StrOutputParser'}, 'id': 3, 'type': 'runnable'}, {'data': 'StrOutputParserOutput', 'id': 4, 'type': 'schema'}]}, 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'], 'kwargs': {'first': {'graph': {'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}], 'nodes': [{'data': 'PromptInput', 'id': 0, 'type': 'schema'}, {'data': {'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'name': 'ChatPromptTemplate'}, 'id': 1, 'type': 'runnable'}, {'data': 'ChatPromptTemplateOutput', 'id': 2, 'type': 'schema'}]}, 'id': ['langchain', 'schema', 'runnable', 'RunnableBinding'], 'kwargs': {'bound': {'graph': {'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}], 'nodes': [{'data': 'PromptInput', 'id': 0, 'type': 'schema'}, {'data': {'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'name': 'ChatPromptTemplate'}, 'id': 1, 'type': 'runnable'}, {'data': 'ChatPromptTemplateOutput', 'id': 2, 'type': 'schema'}]}, 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['query'], 'messages': [{'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'graph': {'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}], 'nodes': [{'data': 'PromptInput', 'id': 0, 'type': 'schema'}, {'data': {'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'name': 'PromptTemplate'}, 'id': 1, 'type': 'runnable'}, {'data': 'PromptTemplateOutput', 'id': 2, 'type': 'schema'}]}, 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['query'], 'partial_variables': {}, 'template': 'You are a helpful and harmless AI assistant. \\n\\nHuman: {query}', 'template_format': 'f-string'}, 'lc': 1, 'name': 'PromptTemplate', 'type': 'constructor'}}, 'lc': 1, 'type': 'constructor'}], 'partial_variables': {}}, 'lc': 1, 'name': 'ChatPromptTemplate', 'type': 'constructor'}, 'config': {'tags': ['Tracing Example']}, 'config_factories': [], 'custom_input_type': None, 'custom_output_type': None, 'kwargs': {}}, 'lc': 1, 'name': 'ChatPromptTemplate', 'type': 'constructor'}, 'last': {'graph': {'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}], 'nodes': [{'data': 'StrOutputParserInput', 'id': 0, 'type': 'schema'}, {'data': {'id': ['langchain', 'schema', 'output_parser', 'StrOutputParser'], 'name': 'StrOutputParser'}, 'id': 1, 'type': 'runnable'}, {'data': 'StrOutputParserOutput', 'id': 2, 'type': 'schema'}]}, 'id': ['langchain', 'schema', 'runnable', 'RunnableBinding'], 'kwargs': {'bound': {'graph': {'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}], 'nodes': [{'data': 'StrOutputParserInput', 'id': 0, 'type': 'schema'}, {'data': {'id': ['langchain', 'schema', 'output_parser', 'StrOutputParser'], 'name': 'StrOutputParser'}, 'id': 1, 'type': 'runnable'}, {'data': 'StrOutputParserOutput', 'id': 2, 'type': 'schema'}]}, 'id': ['langchain', 'schema', 'output_parser', 'StrOutputParser'], 'kwargs': {}, 'lc': 1, 'name': 'StrOutputParser', 'type': 'constructor'}, 'config': {'tags': ['Tracing Example']}, 'config_factories': [], 'custom_input_type': None, 'custom_output_type': None, 'kwargs': {}}, 'lc': 1, 'name': 'StrOutputParser', 'type': 'constructor'}, 'middle': [{'graph': {'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}], 'nodes': [{'data': 'ChatAnthropicInput', 'id': 0, 'type': 'schema'}, {'data': {'id': ['langchain_anthropic', 'chat_models', 'ChatAnthropic'], 'name': 'ChatAnthropic'}, 'id': 1, 'type': 'runnable'}, {'data': 'ChatAnthropicOutput', 'id': 2, 'type': 'schema'}]}, 'id': ['langchain', 'schema', 'runnable', 'RunnableBinding'], 'kwargs': {'bound': {'graph': {'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}], 'nodes': [{'data': 'ChatAnthropicInput', 'id': 0, 'type': 'schema'}, {'data': {'id': ['langchain_anthropic', 'chat_models', 'ChatAnthropic'], 'name': 'ChatAnthropic'}, 'id': 1, 'type': 'runnable'}, {'data': 'ChatAnthropicOutput', 'id': 2, 'type': 'schema'}]}, 'id': ['langchain_anthropic', 'chat_models', 'ChatAnthropic'], 'lc': 1, 'name': 'ChatAnthropic', 'repr': \"ChatAnthropic(model='claude-3-opus-20240229', anthropic_api_key=SecretStr('**********'), _client=<anthropic.Anthropic object at 0x120795b50>, _async_client=<anthropic.AsyncAnthropic object at 0x120700190>)\", 'type': 'not_implemented'}, 'config': {'run_name': 'Anthropic-Example', 'tags': ['Tracing Example']}, 'config_factories': [], 'custom_input_type': None, 'custom_output_type': None, 'kwargs': {}}, 'lc': 1, 'name': 'ChatAnthropic', 'type': 'constructor'}], 'name': None}, 'lc': 1, 'name': 'RunnableSequence', 'type': 'constructor'}, events=[{'name': 'start', 'time': '2024-04-12T02:26:25.974846+00:00'}, {'name': 'end', 'time': '2024-04-12T02:26:41.244250+00:00'}], inputs={'query': 'Can you create a social media post for my blog about Artificial Intelligence and its impacts on our daily lives?'}, outputs={'output': \"Sure, I'd be happy to help you create a social media post for your blog about Artificial Intelligence (AI) and its impacts on our daily lives. Here's a sample post you can use or modify:\\n\\nTitle: The Impact of Artificial Intelligence on Our Daily Lives\\n\\nArtificial Intelligence is transforming the way we live, work, and interact with the world around us. From virtual assistants like Siri and Alexa to personalized recommendations on streaming platforms, AI is becoming increasingly integrated into our daily routines.\\n\\nBut the impact of AI goes far beyond convenience and entertainment. In healthcare, AI is being used to analyze medical images, assist in diagnosis, and even develop new treatments. In education, AI-powered tools are providing personalized learning experiences and helping teachers to better understand student needs.\\n\\nHowever, as with any new technology, there are also concerns about the potential downsides of AI. From job displacement to privacy risks, it's important that we consider the ethical implications of AI and work to ensure that its development and deployment are guided by principles of transparency, accountability, and fairness.\\n\\nWhat do you think about the impact of AI on our daily lives? Share your thoughts in the comments below and read more on my blog! [link to your blog post]\\n\\n#AI #ArtificialIntelligence #Technology #FutureTech #Innovation #Ethics\\n\\nFeel free to customize this post to fit your specific blog post and audience. Good luck with your blog!\"}, reference_example_id=None, parent_run_id=None, tags=[], session_id=UUID('d264aa8b-fbf9-44e4-af78-37edf5252812'), child_run_ids=[UUID('5e8df45d-0e60-4c76-beea-de3a4d6cfec9'), UUID('694436cb-bc2a-40d7-b498-714da47e96da'), UUID('1f600091-1fd9-42dd-b6ab-73bbeb21252d')], child_runs=None, feedback_stats=None, app_path='/o/d4f5e421-8f06-44c3-b1e0-8e69e2884cef/projects/p/d264aa8b-fbf9-44e4-af78-37edf5252812/r/e6e9188e-6974-44f9-b4f8-8524e813ffaf?trace_id=e6e9188e-6974-44f9-b4f8-8524e813ffaf&start_time=2024-04-12T02:26:25.974846', manifest_id=None, status='success', prompt_tokens=35, completion_tokens=286, total_tokens=321, first_token_time=None, total_cost=None, prompt_cost=None, completion_cost=None, parent_run_ids=[], trace_id=UUID('e6e9188e-6974-44f9-b4f8-8524e813ffaf'), dotted_order='20240412T022625974846Ze6e9188e-6974-44f9-b4f8-8524e813ffaf', in_dataset=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = client.read_run(cb.latest_run.id)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project '9c32d8c0-03fd-49ff-8561-296def7832e9' at:\n",
      "https://smith.langchain.com/o/d4f5e421-8f06-44c3-b1e0-8e69e2884cef/datasets/b81aa58f-4785-4a3c-8ce4-81954a537065/compare?selectedSessions=5ef6a667-92ed-41c7-9351-e3f428ad7486\n",
      "\n",
      "View all tests for Dataset Weather API Generative Output at:\n",
      "https://smith.langchain.com/o/d4f5e421-8f06-44c3-b1e0-8e69e2884cef/datasets/b81aa58f-4785-4a3c-8ce4-81954a537065\n",
      "[------------------------------------------------->] 13/13"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.COT Contextual Accuracy</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>676c7a67-c8d5-428b-8156-bbd4968c0cd8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.364477</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.277350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.573565</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.961449</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.279264</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.888144</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.181731</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.COT Contextual Accuracy error  execution_time  \\\n",
       "count                          13.000000     0       13.000000   \n",
       "unique                               NaN     0             NaN   \n",
       "top                                  NaN   NaN             NaN   \n",
       "freq                                 NaN   NaN             NaN   \n",
       "mean                            0.076923   NaN        3.364477   \n",
       "std                             0.277350   NaN        0.551714   \n",
       "min                             0.000000   NaN        2.573565   \n",
       "25%                             0.000000   NaN        2.961449   \n",
       "50%                             0.000000   NaN        3.279264   \n",
       "75%                             0.000000   NaN        3.888144   \n",
       "max                             1.000000   NaN        4.181731   \n",
       "\n",
       "                                      run_id  \n",
       "count                                     13  \n",
       "unique                                    13  \n",
       "top     676c7a67-c8d5-428b-8156-bbd4968c0cd8  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import langsmith\n",
    "from langchain import smith\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Replace with the chat model you want to test\n",
    "my_llm = ChatGoogleGenerativeAI(google_api_key=google_api_key, model=\"gemini-pro\")\n",
    "\n",
    "# Define the evaluators to apply\n",
    "eval_config = smith.RunEvalConfig(\n",
    "    evaluators=[\"cot_qa\"],\n",
    "    custom_evaluators=[],\n",
    "    eval_llm=ChatOpenAI(\n",
    "        model=\"gpt-4-turbo\", temperature=0, openai_api_key=openai_api_key\n",
    "    ),\n",
    ")\n",
    "\n",
    "client = langsmith.Client()\n",
    "chain_results = client.run_on_dataset(\n",
    "    dataset_name=\"Weather API Generative Output\",\n",
    "    llm_or_chain_factory=my_llm,\n",
    "    evaluation=eval_config,\n",
    "    project_name=str(uuid4()),\n",
    "    concurrency_level=5,\n",
    "    verbose=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langsmith-py3.11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
